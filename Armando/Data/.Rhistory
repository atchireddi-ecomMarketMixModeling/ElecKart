install.packages("rpart")
install.packages("rattle")
install.packages("rpart.plot")
install.packages("RColorBrewer")
library(dplyr)
install.packages("dplyr")
install.packages("ggvis")
data("AirPassengers")
ap=AirPassengers
ap
class(ap)
plot(ap, col=c("blue"))
plot(decompose(ap))
plot(stl(ap, "periodic"))
ap.decom<-plot(decompose(ap, type = "mult"))
trend=ap.decom$trend
seasonal=ap.decom$seasonal
ts.plot(cbind(trend, trend*seasonal), lty = 1:2)
ap.decom=decompose(ap,type="mult")
plot(ap.decom)
trend=ap.decom$trend
trend
seasonal=ap.decom$seasonal
seasonal
ts.plot(cbind(trend,trend*seasonal),lty=1:2)
plot(stl(ap,"periodic"))
ts.plot(cbind(trend,trend*seasonal),lty=1:2)
w=rnorm(200)
x=cumsum(w)
plot.ts(w, col="blue")
plot.ts(x, col="red")
plot.ts(cumsum(rnorm(200)), col = "red")
install.packages("randomForest")
data("AirPassengers"); ap=AirPassengers
ap.decom=decompose(ap, type = "mult")
plot(ap.decom)
random=ap.decom$random
random
pacf(random,na.action = na.exclude)
acf(random,na.action = na.exclude)
#model 1
m1=arima(random, order = c(1,0,0))
res1=residuals(m1)
m1
shapiro.test(res1)
confint(m1)
predict(m1,n.ahead = 10)
m2=arima(random,order = c(2,0,0))
res2=residuals(m2)
m2
shapiro.test(res2)
confint(m2)
predict(m2,n.ahead = 10)
cycle(ap)
time(ap)
m3=1m(ap~0+time(ap))
m3=1m(ap~0+time(ap)+factor(cycle(ap)))
m1=1m(ap~0+time(ap)+factor(cycle(ap)))
m1=1m(ap~time(ap)+factor(cycle(ap)))
m1<-1m(ap~time(ap)+factor(cycle(ap)))
m1=lm(ap~time(ap)+factor(cycle(ap)))
m1=lm(ap~0+time(ap)+factor(cycle(ap)))
m1
summary(m1)
m3=residuals(m1)
pacf(m3)
install.packages("arules")
install.packages("arulesViz")
library(arules)
data("AdultUCI")
View(AdultUCI)
Adult=as(AdultUCI, "transactions")
## create a demo file using basket format for the example
data <- paste("item1,item2","item1","item2,item3", sep="\n")
cat(data)
write(data, file = "demo_basket")
## read demo data
tr <- read.transactions("demo_basket", format = "basket", sep=",")
inspect(tr)
## create a demo file using single format for the example
## column 1 contains the transaction ID and column 2 contains one item
data <- paste("trans1 item1", "trans2 item1","trans2 item2", sep ="\n")
cat(data)
write(data, file = "demo_single")
## read demo data
tr <- read.transactions("demo_single", format = "single", cols = c(1,2))
inspect(tr)
#Packages to be used:
#recommenderlab
#ggplot
#In this case study, we will look at :
#Loading movie lens package from recommenderlabs
library(recommenderlab)
data("MovieLense")
class(MovieLense)
r <- as(MovieLense, "realRatingMatrix")
#Packages to be used:
#recommenderlab
#ggplot
#In this case study, we will look at :
#Loading movie lens package from recommenderlabs
install.packages("recommenderlab")
library(recommenderlab)
data("MovieLense")
class(MovieLense)
r <- as(MovieLense, "realRatingMatrix")
install.packages("proxy")
data("MovieLense")
library(recommenderlab)
data("MovieLense")
class(MovieLense)
r <- as(MovieLense, "realRatingMatrix")
install.packages("arules")
install.packages("arules")
library(recommenderlab)
data("MovieLense")
install.packages("proxy")
library(recommenderlab)
data("MovieLense")
#Packages to be used:
#recommenderlab
#ggplot
#In this case study, we will look at :
#Loading movie lens package from recommenderlabs
library(recommenderlab)
data("MovieLense")
install.packages("proxy")
require("proxy")
require('proxy')
install.packages('proxy')
install.packages('recommenderlab', dependencies = TRUE)
library(recommenderlab)
data("MovieLense")
#Packages to be used:
#recommenderlab
#ggplot
#In this case study, we will look at :
#Loading movie lens package from recommenderlabs
library(recommenderlab)
data("MovieLense")
install.packages('proxy', dependencies = TRUE)
library(recommenderlab)
data("MovieLense")
class(MovieLense)
r <- as(MovieLense, "realRatingMatrix")
dimnames(r)
rowCounts(r)
colCounts(r)
rowMeans(r)
movies_df <- as(r, "data.frame")
str(movies_df)
View(movies_df)
#How similar are the first ten users are with each other
similar_users <- similarity(MovieLense[1:10, ],
method = "cosine",
which = "users")
#Similarity matrix
as.matrix(similar_users)
#Visualise similarity matrix
image(as.matrix(similar_users), main = "User similarity")
#Inference
#Users 1, 3, 4 and 9 are similar
#How similar are the first five items are with each other
similar_items <- similarity(MovieLense[,1:10 ],
method = "cosine",
which = "items")
as.matrix(similar_items)
image(as.matrix(similar_items), main = "Item similarity")
#You can notice more items being similar :Eg items 2 and 6 are similar; 5 and 10 are similar etc.
#--------------------------Understand users and ratings----------#
# Visualizing ratings
library(ggplot2)
qplot(getRatings(MovieLense), binwidth = 1,
main = "Histogram of ratings", xlab = "Rating")
summary(getRatings(MovieLense)) # Skewed to the right
qplot(getRatings(normalize(MovieLense, method = "Z-score")),
main = "Histogram of normalized ratings", xlab = "Rating")
summary(getRatings(normalize(MovieLense, method = "Z-score"))) # seems better
qplot(rowCounts(MovieLense), binwidth = 10,
main = "Movies Rated on average",
xlab = "# of users",
ylab = "# of movies rated")
#Most users rate less number of movies.
#Very few users have rated more movies
#--------------------------Recommendation models ----------------#
#List of models available
recommender_models <- recommenderRegistry$get_entries(dataType = "realRatingMatrix")
names(recommender_models)# 9 types of models
#description of recommendation system algorithms/models used
lapply(recommender_models, "[[", "description")
#This gives you different types of recommendation models
#In this case study , let's compare user based and item based
#collaborative filtering
#checking the parameters of these two models
recommender_models$IBCF_realRatingMatrix$parameters
#Divide data into test
scheme <- evaluationScheme(MovieLense, method = "split", train = .9,
k = 1, given = 2, goodRating = 4)
?evaluationScheme
scheme
algorithms <- list(
"user-based CF" = list(name="UBCF", param=list(normalize = "Z-score",
method="Cosine",
nn=30, minRating=3)),
"item-based CF" = list(name="IBCF", param=list(normalize = "Z-score"
))
)
# run algorithms, predict next n movies
results <- evaluate(scheme, algorithms, n=c(1, 3, 5, 10, 15, 20))
class(results)
# Draw ROC curve
plot(results, annotate = 1:4, legend="topleft")
comics
install.packages("readr")
install.packages("lubridate")
install.packages("tidyr")
install.packages("stringR")
install.packages("stringr")
# \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Code is Poetry >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
# Define Adstock Rate
adstock_rate = 0.50
# Create Data
advertising = c(117.913, 120.112, 125.828, 115.354, 177.090, 141.647, 137.892,   0.000,   0.000,   0.000,   0.000,
0.000,   0.000,   0.000,   0.000,   0.000,   0.000, 158.511, 109.385,  91.084,  79.253, 102.706,
78.494, 135.114, 114.549,  87.337, 107.829, 125.020,  82.956,  60.813,  83.149,   0.000,   0.000,
0.000,   0.000,   0.000,   0.000, 129.515, 105.486, 111.494, 107.099,   0.000,   0.000,   0.000,
0.000,   0.000,   0.000,   0.000,   0.000,   0.000,   0.000,   0.000)
# Calculate Advertising Adstock
# Credit: http://stackoverflow.com/questions/14372880/simple-examples-of-filter-function-recursive-option-specifically
adstocked_advertising = filter(x=advertising, filter=adstock_rate, method="recursive")
# Alternative Method Using Loops Proposed by Linh Tran
adstocked_advertising = numeric(length(advertising))
adstocked_advertising[1] = advertising[1]
for(i in 2:length(advertising)){
adstocked_advertising[i] = advertising[i] + adstock_rate * adstocked_advertising[i-1]
}
# Graph Data
plot(seq(1,length(advertising)), advertising, type="h",
xlab="Time (Usually in Weeks)", ylab="Advertising",
ylim=c(0, max(c(advertising, adstocked_advertising))),
frame.plot=FALSE)
lines(adstocked_advertising)
setwd("~/GitHub/UpGrad-Projects/Capstone-ElecKart/Data")
setwd("~/GitHub/UpGrad-Projects/Capstone-ElecKart")
# ***************************************************************************
#                   LOAD LIBRARY ----
# ***************************************************************************
library(lubridate)
library(dplyr)
library(ggplot2)
library(MASS)
library(car)
library(Hmisc)   # describe
# ***************************************************************************
#                   LOAD DATA ---- Transaction Data ----
# ***************************************************************************
# Make sure you are in current directory as in R-file is in. Should I do a commit?yes..
ce_data <- read.csv('./data/ConsumerElectronics.csv',stringsAsFactors = FALSE)
str(ce_data)
# ***************************************************************************
#                   DATA CLEANING ----
# ***************************************************************************
head(ce_data)
# . . . .   Outlier Treatment ----
# Remove orders before July'15 and after June'16
ce_data$order_date <- format(as.POSIXct(ce_data$order_date,format='%Y-%m-%d'),
format='%Y-%m-%d')
ce_data$order_date <- as.Date(ce_data$order_date, format = "%Y-%m-%d")
ce_data <- subset(ce_data, order_date > "2015-6-30" & order_date < "2016-7-1")
ce_data$List_Price <- as.integer(ce_data$gmv / ce_data$units)
View(ce_data)
ce_data$Promotion <- as.integer((ce_data$product_mrp - ce_data$List_Price) / ce_data$product_mrp)
View(ce_data)
summary(ce_data$gmv)
setwd("~/GitHub/Capstone-ElecKart/Data")
# ***************************************************************************
#                   LOAD LIBRARY ----
# ***************************************************************************
library(lubridate)
library(dplyr)
library(ggplot2)
library(MASS)
library(car)
library(Hmisc)   # describe
# ***************************************************************************
#                   LOAD DATA ---- Transaction Data ----
# ***************************************************************************
# Make sure you are in current directory as in R-file is in. Should I do a commit?yes..
ce_data <- read.csv('./data/ConsumerElectronics.csv',stringsAsFactors = FALSE)
str(ce_data)
# ***************************************************************************
#                   DATA CLEANING ----
# ***************************************************************************
head(ce_data)
# . . . .   Outlier Treatment ----
# Remove orders before July'15 and after June'16
ce_data$order_date <- format(as.POSIXct(ce_data$order_date,format='%Y-%m-%d'),
format='%Y-%m-%d')
ce_data$order_date <- as.Date(ce_data$order_date, format = "%Y-%m-%d")
ce_data <- subset(ce_data, order_date > "2015-6-30" & order_date < "2016-7-1")
setwd("~/GitHub/Capstone-ElecKart/Data")
# ***************************************************************************
#                   LOAD LIBRARY ----
# ***************************************************************************
library(lubridate)
library(dplyr)
library(ggplot2)
library(MASS)
library(car)
library(Hmisc)   # describe
# ***************************************************************************
#                   LOAD DATA ---- Transaction Data ----
# ***************************************************************************
# Make sure you are in current directory as in R-file is in. Should I do a commit?yes..
ce_data <- read.csv('./data/ConsumerElectronics.csv',stringsAsFactors = FALSE)
str(ce_data)
# ***************************************************************************
#                   DATA CLEANING ----
# ***************************************************************************
head(ce_data)
# . . . .   Outlier Treatment ----
# Remove orders before July'15 and after June'16
ce_data$order_date <- format(as.POSIXct(ce_data$order_date,format='%Y-%m-%d'),
format='%Y-%m-%d')
ce_data$order_date <- as.Date(ce_data$order_date, format = "%Y-%m-%d")
ce_data <- subset(ce_data, order_date > "2015-6-30" & order_date < "2016-7-1")
ce_data <- read.csv('./data/ConsumerElectronics.csv',stringsAsFactors = FALSE)
